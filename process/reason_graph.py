import random
import time
from collections import deque
import collections
import numpy as np
import torch
from openai import OpenAI
from torch_geometric.nn import GNNExplainer

from process.match.deephunter.graphmatchnet import GraphMatchingScorer
from process.match.test_model import build_model
from process.match.evaluation import compute_similarity
from process.match.test_model import get_default_config


# TODO 1ã€æŠŠçœŸå®æ•°æ®æ•°æ®é›†æˆä¸Šæ¥ 2ã€ä¸²è”åŒ¹é…å¯è§£é‡Šæ€§ 3ã€triple 4ã€tuoyuæµ‹è¯•
def reshape_and_split_tensor(tensor, n_splits):
    """Reshape and split a 2D tensor along the last dimension.

    Args:
      tensor: a [num_examples, feature_dim] tensor.  num_examples must be a
        multiple of `n_splits`.
      n_splits: int, number of splits to split the tensor into.

    Returns:
      splits: a list of `n_splits` tensors.  The first split is [tensor[0],
        tensor[n_splits], tensor[n_splits * 2], ...], the second split is
        [tensor[1], tensor[n_splits + 1], tensor[n_splits * 2 + 1], ...], etc..
    """
    feature_dim = tensor.shape[-1]
    tensor = torch.reshape(tensor, [-1, feature_dim * n_splits])
    tensor_split = []
    for i in range(n_splits):
        tensor_split.append(tensor[:, feature_dim * i: feature_dim * (i + 1)])
    return tensor_split


def find_important_nodes_and_edges(graph_edge_mask, edge_index, top_k=5, verbose=True):
    """
    è®¡ç®—å›¾ä¸­èŠ‚ç‚¹å’Œè¾¹çš„é‡è¦æ€§å¾—åˆ†ï¼Œå¹¶è¿”å›æ˜ å°„

    Args:
        graph_edge_mask (Tensor): è¾¹çš„é‡è¦æ€§åˆ†æ•° (shape: [num_edges])
        edge_index (Tensor): è¾¹çš„ç´¢å¼•çŸ©é˜µ (shape: [2, num_edges])
        top_k (int): æ‰“å°å‰ top_k ä¸ªé‡è¦èŠ‚ç‚¹å’Œè¾¹
        verbose (bool): æ˜¯å¦æ‰“å°è¯¦ç»†ä¿¡æ¯

    Returns:
        node_importance_dict: {node_id: importance_score}
        edge_importance_list: [((src, dst), score), ...]
    """
    edge_mask_np = graph_edge_mask.detach().cpu().numpy()
    edge_index_np = edge_index.detach().cpu().numpy()
    # èŠ‚ç‚¹é‡è¦æ€§åˆå§‹åŒ–
    num_nodes = edge_index_np.max() + 1
    node_importance = [0.0] * num_nodes

    # ç´¯åŠ è¾¹çš„é‡è¦æ€§åˆ°ç›¸é‚»èŠ‚ç‚¹
    for idx, score in enumerate(edge_mask_np):
        src, dst = edge_index_np[:, idx]
        node_importance[src] += score
        node_importance[dst] += score
    # æ„å»ºæ˜ å°„ç»“æœ
    node_importance_dict = {i: score for i, score in enumerate(node_importance)}
    edge_importance_list = [((int(edge_index_np[0, i]), int(edge_index_np[1, i])), float(score)) for i, score in
                            enumerate(edge_mask_np)]

    # æ’åº
    sorted_nodes = sorted(node_importance_dict.items(), key=lambda x: x[1], reverse=True)
    sorted_edges = sorted(edge_importance_list, key=lambda x: x[1], reverse=True)

    if verbose:
        print(f"ğŸ“Œ Top-{top_k} é‡è¦èŠ‚ç‚¹:")
        for nid, score in sorted_nodes[:top_k]:
            print(f"  èŠ‚ç‚¹ {nid} â†’ é‡è¦æ€§: {score:.4f}")

        print(f"\nğŸ”— Top-{top_k} é‡è¦è¾¹:")
        for (src, dst), score in sorted_edges[:top_k]:
            print(f"  è¾¹ ({src} â†’ {dst}) â†’ é‡è¦æ€§: {score:.4f}")

    return node_importance_dict, edge_importance_list

def call_llm(template):
    """
    é€šç”¨å¤§æ¨¡å‹è°ƒç”¨å°è£…ï¼š
    - è¾“å…¥ï¼štemplateï¼ˆpromptå­—ç¬¦ä¸²ï¼‰
    - è¾“å‡ºï¼šLLMå®Œæ•´è¿”å›çš„æ–‡æœ¬å†…å®¹
    """
    client = OpenAI(
        api_key="sk-xhUZwtWJmekrtdX2hLvnC6nnuNSfe6qNIidWbzRIQBoZCEMa",
        base_url="https://api.chatanywhere.tech/v1"
    )

    response = client.chat.completions.create(
        model="gpt-4",
        messages=[{"role": "user", "content": template}]
    )

    answer = response.choices[0].message.content.strip()
    return answer


def bfs_igraph_multi_start(G, start_vertices):
    """
    æ”¯æŒå¤šä¸ªèµ·ç‚¹çš„ BFSï¼Œè®°å½•æ‰€æœ‰å®Œæ•´è·¯å¾„
    :param graph: igraph.Graph å¯¹è±¡
    :param select_k: æ¯ä¸ªèŠ‚ç‚¹éšæœºé€‰æ‹©çš„é‚»å±…æ•°é‡
    :return: æ‰€æœ‰å®Œæ•´è·¯å¾„ (list)
    """
    paths = {}  # è®°å½•æ¯ä¸ªèŠ‚ç‚¹IDçš„å®Œæ•´è·¯å¾„
    final_paths = []  # å­˜æ”¾å®Œæ•´è·¯å¾„ç»“æœ

    # BFS åˆå§‹åŒ–
    visited = set()
    queue = deque()

    # åˆå§‹åŒ–å¤šä¸ªèµ·ç‚¹
    print(f"åˆå§‹èŠ‚ç‚¹{start_vertices}")
    for start in start_vertices:
        queue.append(start)
        visited.add(start)
        paths[start] = [start]
    while queue:
        node = queue.popleft()
        neighbors_idx = set()
        for nbr_idx in G.neighbors(int(node), mode="ALL"):
            if nbr_idx not in visited and nbr_idx not in neighbors_idx:
                neighbors_idx.add(nbr_idx)
        print(f"node{node} have neighbors{neighbors_idx}")
        # æ¢ç´¢
        if neighbors_idx:
            # éšæœºé€‰æ‹© K ä¸ªé‚»å±…æ‰©å±•
            # âœ… TODO: LLM æ§åˆ¶é€‰æ‹©ç­–ç•¥ï¼ˆç¤ºä¾‹ï¼šLLM è®©ä½ é€‰æˆ–ç­›é€‰ neighborï¼‰éšæœºé€‰æ‹© K ä¸ªé‚»å±…æ‰©å±•
            neighbors_with_relation = []
            for neighbor_idx in neighbors_idx:
                try:
                    edge_id = G.get_eid(node, neighbor_idx, directed=False)
                    relation = G.es[edge_id]["actions"]
                    neighbors_with_relation.append((node, relation, neighbor_idx))
                except Exception as e:
                    print(f" æ— æ³•è·å–è¾¹ {node} -> {neighbor_idx}ï¼š{e}")
            selected_neighbors = llm_select_neighbors(G, node, neighbors_with_relation, paths[node])
            print(
                f"node {node} éšæœºé€‰æ‹©åä¸‰å…ƒç»„ {selected_neighbors}")
            for src, relation, dst in selected_neighbors:
                visited.add(dst)
                queue.append(dst)
                paths[dst] = paths[node] + [relation, dst]  # ç´¯åŠ ä¸‰å…ƒç»„è·¯å¾„
                print(f"æ¢ç´¢çš„è·¯å¾„ä¸º src: {src} dst: {dst}, path[dst]: {paths[dst]}")

        # ç»ˆæ­¢åˆ¤æ–­
        temp_path = "->".join(map(str, paths[node]))
        final_paths = [p for p in final_paths if not temp_path.startswith(p + "->")]
        final_paths.append(temp_path)
        if llm_should_stop(G, final_paths):
            print("LLMåˆ¤å®šåœæ­¢ï¼ŒBFSé€€å‡º")
            break

    print(f"\næœ€ç»ˆå®Œæ•´è·¯å¾„é›†åˆ: {final_paths}")
    return final_paths


def llm_select_neighbors(G, current_node, candidate_triples, current_path, llm = False):
    """
    è°ƒç”¨å¤§æ¨¡å‹ LLM å†³ç­–ï¼šä»å€™é€‰é‚»å±…ä¸‰å…ƒç»„ä¸­é€‰æ‹©è¦èµ°çš„è¾¹
    :param current_node: å½“å‰èŠ‚ç‚¹
    :param candidate_triples: [(src, relation, dst), ...]
    :param current_path: å½“å‰å·²èµ°çš„è·¯å¾„ï¼ˆä¸‰å…ƒç»„è·¯å¾„ï¼‰
    :return: LLM é€‰æ‹©çš„ä¸‰å…ƒç»„åˆ—è¡¨
    """
    if llm:
        # æ ¼å¼åŒ–è·¯å¾„å’Œå€™é€‰è¾¹ä¸ºå­—ç¬¦ä¸²
        str_to_id_map = {}
        triples_str_parts = []

        for s, r, o in candidate_triples:
            s_prop = G.vs[s]["properties"]
            o_prop = G.vs[o]["properties"]
            triple_str = f"('{s_prop}', '{r}', '{o_prop}')"
            triples_str_parts.append(triple_str)
            str_to_id_map[(s_prop, r, o_prop)] = (s, r, o)

        triples_str = ", ".join(triples_str_parts)
        template = (
            f"å½“å‰èŠ‚ç‚¹ä¸ºï¼š{current_node}\n"
            f"å½“å‰å·²èµ°è·¯å¾„ä¸ºï¼š{current_path}\n"
            f"å€™é€‰ä¸‰å…ƒç»„ä¸ºï¼š[{triples_str}]\n"
            "è¯·ä»å€™é€‰ä¸‰å…ƒç»„ä¸­é€‰æ‹©ä½ è®¤ä¸ºæœ€ä¼˜çš„ï¼ˆå¯é€‰æ‹©å¤šä¸ªï¼‰ï¼Œ\n"
            "ç›´æ¥è¿”å› Python åˆ—è¡¨æ ¼å¼ï¼Œä¾‹å¦‚ï¼š [('A', 'rel1', 'B'), ('B', 'rel2', 'C')]ã€‚"
        )

        # è°ƒç”¨å¤§æ¨¡å‹
        response = call_llm(template)
        print(f"LLMé€‰æ‹©é‚»å±…å›å¤ï¼š{response}")

        # å°è¯•è§£æè¿”å›å€¼ä¸ºä¸‰å…ƒç»„åˆ—è¡¨
        try:
            selected = eval(response)
            # è¿˜åŸå­—ç¬¦ä¸²ä¸‰å…ƒç»„ â†’ åŸå§‹ ID ä¸‰å…ƒç»„
            selected_triples = []
            for triple in selected:
                if isinstance(triple, tuple) and len(triple) == 3:
                    key = tuple(triple)
                    if key in str_to_id_map:
                        selected_triples.append(str_to_id_map[key])
            if selected_triples:
                return selected_triples
        except Exception as e:
            print(f"LLMè¿”å›æ— æ³•è§£ææˆ–åŒ¹é…å¤±è´¥ï¼Œé»˜è®¤éšæœºé€‰ï¼š{e}")
    else:
        # å¦‚æœ LLM è¿”å›å‡ºé”™ï¼Œéšæœº fallback
        select_k = 2
        return random.sample(candidate_triples, min(select_k, len(candidate_triples)))

def convert_path_ids_to_names(path_lines, G):
    converted = []
    nodeName = []
    for line in path_lines:
        parts = line.strip().split("->")
        name_parts = []
        try:
            for i, part in enumerate(parts):
                if i % 2 == 0:
                    # å¶æ•°ä½ï¼šèŠ‚ç‚¹ ID â†’ åå­—
                    name_parts.append(G.vs[int(part)]["properties"])
                    nodeName.append(G.vs[int(part)]['name'])
                else:
                    # å¥‡æ•°ä½ï¼šè¾¹åï¼ŒåŸæ ·ä¿ç•™
                    name_parts.append(part)
            converted.append("->".join(name_parts))
        except (ValueError, IndexError, KeyError) as e:
            converted.append(f"[æ— æ•ˆè·¯å¾„] {line}")
    with open("node_names.txt", "w", encoding="utf-8") as f:
        for name in nodeName:
            f.write(name + "\n")
    return converted

def llm_should_stop(G, final_paths, llm = False):
    """
    è°ƒç”¨å¤§æ¨¡å‹ LLM åˆ¤æ–­ï¼šæ ¹æ®å½“å‰å®Œæ•´è·¯å¾„é›†åˆï¼Œå†³å®šæ˜¯å¦åœæ­¢BFS
    å¤§æ¨¡å‹ä¼šåŸºäºä»¥ä¸‹è§„åˆ™ä½œç­”ï¼š
    - å¦‚æœè·¯å¾„æ•°é‡è¶…è¿‡3æ¡ï¼Œå»ºè®®åœæ­¢
    - å¦‚æœè·¯å¾„ä¸­åŒ…å«å…³é”®èŠ‚ç‚¹ 'J'ï¼Œå»ºè®®åœæ­¢
    """
    # åŠ¨æ€æ‹¼æ¥è·¯å¾„åˆ—è¡¨åˆ° prompt ä¸­
    final_paths_names = convert_path_ids_to_names(final_paths, G)
    if llm:
        template = (
            f"ä»¥ä¸‹æ˜¯å½“å‰å®Œæ•´è·¯å¾„é›†åˆï¼š{final_paths_names}ã€‚\n"
            "è¯·åˆ¤æ–­ï¼šæ˜¯å¦åº”è¯¥åœæ­¢éå†ï¼Ÿ\n"
            "è§„åˆ™ï¼šå¦‚æœè·¯å¾„æ•°é‡è¶…è¿‡5æ¡ æˆ– è·¯å¾„ä¸­åŒ…å«å…³é”®èŠ‚ç‚¹ 'J'ï¼Œæˆ–è€…å•æ¡è·¯å¾„é•¿åº¦è¶…è¿‡5, åˆ™å»ºè®®åœæ­¢ã€‚\n"
            "è¯·ç›´æ¥å›ç­”ï¼šæ˜¯ æˆ– å¦ã€‚"
        )

        # è°ƒç”¨å°è£…å¥½çš„ LLM
        response = call_llm(template)
        print(f"final_paths: {final_paths} å¤§æ¨¡å‹å›å¤ï¼š{response}")

        # è‡ªåŠ¨è¯†åˆ«LLMå›ç­”
        if "æ˜¯" in response or "yes" in response.lower():
            print("LLMåˆ¤å®šï¼šåœæ­¢")
            return True
        else:
            print("LLMåˆ¤å®šï¼šç»§ç»­æœç´¢")
            return False
    else:
        if len(final_paths) > 5:
            print("è·¯å¾„æ€»æ•° > 5ï¼Œåœæ­¢ã€‚")
            return True
        print("ç¡¬è§„åˆ™åˆ¤å®šï¼šç»§ç»­æœç´¢")
        return False

def _pack_batch(graphs, node_embeddings, edge_embeddings):
    """Pack a batch of graphs into a single `GraphData` instance.
Args:
  graphs: a list of generated networkx graphs.
Returns:
  graph_data: a `GraphData` instance, with node and edge indices properly
    shifted.
"""
    Graphs = []
    for graph in graphs:
        Graphs.append(graph)
    graphs = Graphs
    from_idx = []
    to_idx = []
    graph_idx = []
    node_names = []
    edge_relations = []

    n_total_nodes = 0
    n_total_edges = 0
    for i, g in enumerate(graphs):
        n_nodes = g.vcount()
        n_edges = g.ecount()
        # æ£€æŸ¥æ˜¯å¦ä¸ºç©ºå›¾
        if n_nodes == 0:
            print(f"[è­¦å‘Š] å›¾ {i} æ²¡æœ‰èŠ‚ç‚¹ï¼Œè·³è¿‡ï¼")
            continue

        if n_edges == 0:
            print(f"[è­¦å‘Š] å›¾ {i} æ²¡æœ‰è¾¹ï¼Œè·³è¿‡ï¼")
            continue

        edges = np.array(g.get_edgelist(), dtype=np.int32)
        # shift the node indices for the edges
        from_idx.append(edges[:, 0] + n_total_nodes)
        to_idx.append(edges[:, 1] + n_total_nodes)
        graph_idx.append(np.ones(n_nodes, dtype=np.int32) * i)
        node_names.extend([g.vs[j]['name'] for j in range(n_nodes)])
        edge_relations.extend([
            g.es[k]['actions'] if 'actions' in g.es[k].attributes() else "undefined_relation"
            for k in range(n_edges)
        ])

        n_total_nodes += n_nodes
        n_total_edges += n_edges


    GraphData = collections.namedtuple('GraphData', [
        'from_idx',
        'to_idx',
        'node_features',
        'edge_features',
        'graph_idx',
        'n_graphs'])

    if not from_idx:
        return None

    node_feature_list = []
    for name in node_names:
        if name in node_embeddings:
            node_feature_list.append(node_embeddings[name])
        else:
            # å¡«ä¸€ä¸ªæ­£ç¡®ç»´åº¦çš„å…¨1å‘é‡ï¼ˆå‡è®¾ç»´åº¦æ˜¯ 30ï¼‰
            node_feature_list.append(np.ones(30, dtype=np.float32))

    node_features = np.array(node_feature_list, dtype=np.float32)
    edge_feature_list = []
    for name in edge_relations:
        if name in edge_embeddings:
            edge_feature_list.append(edge_embeddings[name])
        else:
            # å¡«ä¸€ä¸ªæ­£ç¡®ç»´åº¦çš„å…¨1å‘é‡
            edge_feature_list.append(np.ones(30, dtype=np.float32))
    edge_features = np.array(edge_feature_list, dtype=np.float32)

    return GraphData(
        from_idx=np.concatenate(from_idx, axis=0),
        to_idx=np.concatenate(to_idx, axis=0),
        # this task only cares about the structures, the graphs have no features.
        # setting higher dimension of ones to confirm code functioning
        # with high dimensional features.
        # node_features=np.ones((n_total_nodes, 8), dtype=np.float32),
        node_features=node_features,
        # edge_features=np.ones((n_total_edges, 4), dtype=np.float32),
        edge_features=edge_features,
        graph_idx=np.concatenate(graph_idx, axis=0),
        n_graphs=len(graphs),
    )

def get_graph(batch):
    if len(batch) != 2:
        # if isinstance(batch, GraphData):
        graph = batch
        node_features = torch.from_numpy(graph.node_features)
        edge_features = torch.from_numpy(graph.edge_features)
        from_idx = torch.from_numpy(graph.from_idx).long()
        to_idx = torch.from_numpy(graph.to_idx).long()
        graph_idx = torch.from_numpy(graph.graph_idx).long()
        return node_features, edge_features, from_idx, to_idx, graph_idx
    else:
        graph, labels = batch
        node_features = torch.from_numpy(graph.node_features)
        edge_features = torch.from_numpy(graph.edge_features)
        from_idx = torch.from_numpy(graph.from_idx).long()
        to_idx = torch.from_numpy(graph.to_idx).long()
        graph_idx = torch.from_numpy(graph.graph_idx).long()
        labels = torch.from_numpy(labels).long()
    return node_features, edge_features, from_idx, to_idx, graph_idx, labels

def reson_test_model(pair, node_embeddings, edge_embeddings, model_path="saved_model.pth"):
    start = time.time()
    use_cuda = torch.cuda.is_available()
    device = torch.device('cuda:0' if use_cuda else 'cpu')
    config = get_default_config()
    # ç¡®å®š feature ç»´åº¦
    node_feature_dim = 30
    edge_feature_dim = 30

    model = build_model(config, node_feature_dim, edge_feature_dim)
    model.load_state_dict(torch.load(model_path, map_location=device))
    model.to(device)
    model.eval()

    # å•ç‹¬è·å–ä¸€ä¸ª pair è¿›è¡Œé¢„æµ‹å’Œè§£é‡Š
    packed_graphs = _pack_batch(pair,node_embeddings, edge_embeddings)
    node_features, edge_features, from_idx, to_idx, graph_idx = get_graph(packed_graphs)
    edge_index = torch.stack([from_idx, to_idx], dim=0).to(device)

    # æ¨¡å‹é¢„æµ‹
    with torch.no_grad():
        eval_pairs = model(
            x=node_features.to(device),
            edge_index=edge_index,
            batch=None,
            graph_idx=graph_idx.to(device),
            edge_features=edge_features.to(device),
            n_graphs=2  # ä¸€ä¸ª pairï¼Œä¸¤ä¸ªå›¾
        )
        x, y = reshape_and_split_tensor(eval_pairs, 2)
        similarity = compute_similarity(config, x, y)
        print(f"å›¾å¯¹ç›¸ä¼¼åº¦: {similarity.item():.4f}")

    # è§£é‡Šæ¨¡å‹è¾“å‡º
    explainer = GNNExplainer(model, epochs=200)
    model.eval()
    with torch.backends.cudnn.flags(enabled=False):
        feat_mask, edge_mask = explainer.explain_graph(
            node_features.to(device),
            edge_index,
            graph_idx=graph_idx.to(device),
            edge_features=edge_features.to(device),
            n_graphs=2
        )
    print("å›¾çš„ç‰¹å¾é‡è¦æ€§:", feat_mask)
    print("å›¾çš„è¾¹é‡è¦æ€§:", edge_mask)

    # ç¬¬2å¼ å›¾çš„èŠ‚ç‚¹ç´¢å¼•
    second_graph_nodes = (graph_idx == 1).nonzero(as_tuple=True)[0]
    node_id_map = {old.item(): new for new, old in enumerate(second_graph_nodes)}
    edge_mask_idx = []
    for i, (src, dst) in enumerate(edge_index.t()):  # éå†æ‰€æœ‰è¾¹
        if src.item() in node_id_map and dst.item() in node_id_map:
            edge_mask_idx.append(i)
    edge_mask_idx = torch.tensor(edge_mask_idx, dtype=torch.long)
    second_raw_graph_edge_index = edge_index[:, edge_mask_idx]
    mapped_src = [node_id_map[src.item()] for src in second_raw_graph_edge_index[0]]
    mapped_dst = [node_id_map[dst.item()] for dst in second_raw_graph_edge_index[1]]
    second_graph_edge_index = torch.tensor([mapped_src, mapped_dst], dtype=torch.long)

    second_graph_edge_mask = edge_mask[edge_mask_idx]
    node_scores, edge_scores = find_important_nodes_and_edges(second_graph_edge_mask, second_graph_edge_index)
    # æŒ‰é‡è¦æ€§å¾—åˆ†å€’åºæ’åˆ—èŠ‚ç‚¹
    sorted_nodes = sorted(node_scores.items(), key=lambda x: x[1], reverse=True)
    # å–å‰ k ä¸ªé‡è¦èŠ‚ç‚¹
    k = 5  # å¯ä»¥æ ¹æ®éœ€è¦è®¾ç½®
    top_k_nodes = [node_id for node_id, _ in sorted_nodes[:k]]
    final_full_paths = bfs_igraph_multi_start(pair[1], top_k_nodes)
    print("\næœ€ç»ˆå®Œæ•´è·¯å¾„:")
    for path in final_full_paths:
        print(path)
    print("\næœ€ç»ˆå®Œæ•´è·¯å¾„åç§°:")
    converted = convert_path_ids_to_names(final_full_paths, pair[1])
    for path in converted:
        print(path)


