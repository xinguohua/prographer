# =================è®­ç»ƒ=========================
import os
import sys
sys.path.insert(0, os.path.abspath(os.path.join(os.path.dirname(__file__), '..')))
import torch
from datahandlers import get_handler
from embedders import get_embedder_by_name
from process.match.match import train_model
from process.partition import create_snapshots_from_separate_data
import platform
import yaml

device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

# ã€æ–°å¢ã€‘å¯è‡ªå®šä¹‰çš„è®­ç»ƒå‚æ•°
SEQUENCE_LENGTH = 12       # åºåˆ—é•¿åº¦ï¼Œå¯ä»¥ä¿®æ”¹

print(f"è®­ç»ƒå‚æ•°: åºåˆ—é•¿åº¦={SEQUENCE_LENGTH}")

with open("config.yaml", "r", encoding="utf-8") as f:
    config = yaml.safe_load(f)

system = platform.system().lower()
if "windows" in system:
    env_config = config["local"]
else:
    env_config = config["remote"]

PATH_MAP = env_config["path_map"]

# ======================== é˜¶æ®µ1ï¼šç¼–ç å™¨è®­ç»ƒï¼ˆä½¿ç”¨å…¨éƒ¨æ•°æ®ï¼‰========================
print("="*60)
print("é˜¶æ®µ1ï¼šç¼–ç å™¨è®­ç»ƒï¼ˆä½¿ç”¨å…¨éƒ¨æ•°æ®ï¼‰")
print("="*60)

# è·å–æ•°æ®é›†ç”¨äºç¼–ç å™¨è®­ç»ƒï¼ˆåŠ è½½å…¨éƒ¨æ•°æ®ï¼‰
encoder_handler = get_handler("cadets", True, PATH_MAP)  # train=Trueï¼Œä½†ä¼šåŠ è½½å…¨éƒ¨æ•°æ®
encoder_handler.load(load_all_for_encoder=True)  # ä½¿ç”¨æ–°å‚æ•°åŠ è½½å…¨éƒ¨æ•°æ®

# ä½¿ç”¨å…¨éƒ¨æ•°æ®åˆ›å»ºå¿«ç…§
all_snapshots, benign_start, benign_end, malicious_start, malicious_end = create_snapshots_from_separate_data(encoder_handler)

# è®¾ç½®ç¼–ç å™¨handlerçš„å±æ€§
encoder_handler.snapshots = all_snapshots
encoder_handler.benign_idx_start = benign_start
encoder_handler.benign_idx_end = benign_end
encoder_handler.malicious_idx_start = malicious_start
encoder_handler.malicious_idx_end = malicious_end

print(f"ç¼–ç å™¨è®­ç»ƒæ•°æ®ç»Ÿè®¡:")
print(f"è‰¯æ€§å¿«ç…§ç´¢å¼•èŒƒå›´: {encoder_handler.benign_idx_start} åˆ° {encoder_handler.benign_idx_end}")
print(f"æ¶æ„å¿«ç…§ç´¢å¼•èŒƒå›´: {encoder_handler.malicious_idx_start} åˆ° {encoder_handler.malicious_idx_end}")
print(f"è‰¯æ€§å¿«ç…§æ•°é‡: {benign_end - benign_start + 1 if benign_start != -1 else 0}")
print(f"æ¶æ„å¿«ç…§æ•°é‡: {malicious_end - malicious_start + 1 if malicious_start != -1 else 0}")
print(f"æ€»å…±ç”Ÿæˆäº† {len(all_snapshots)} ä¸ªå¿«ç…§ç”¨äºç¼–ç å™¨è®­ç»ƒ")


with open("communities_all.txt", "w", encoding="utf-8") as f:
    for i, g in enumerate(all_snapshots):
        print(f"æ­£åœ¨å†™ç¤¾åŒº {i} ...")  # æ‰“å°è¿›åº¦
        f.write(f"Community {i}:\n")
        for v in g.vs:
            attrs = v.attributes()
            attr_str = ", ".join([f"{k}={v[k]}" for k in attrs])
            f.write(f"  Vertex {v.index}: {attr_str}\n")
        f.write("\n")

# ğŸ”¥ ä¿å­˜å¿«ç…§æ•°æ®åˆ°æ–‡ä»¶
print("\n--- ä¿å­˜å¿«ç…§æ•°æ®åˆ°æ–‡ä»¶ ---")
import pickle
snapshot_data = {
    'all_snapshots': all_snapshots,
    'benign_idx_start': benign_start,
    'benign_idx_end': benign_end,
    'malicious_idx_start': malicious_start,
    'malicious_idx_end': malicious_end,
}

snapshot_file = "snapshot_data.pkl"
with open(snapshot_file, 'wb') as f:
    pickle.dump(snapshot_data, f)

print(f"âœ… å¿«ç…§æ•°æ®å·²ä¿å­˜åˆ°: {snapshot_file}")
print(f"  - æ€»å¿«ç…§æ•°: {len(all_snapshots)}")
print(f"  - è‰¯æ€§å¿«ç…§èŒƒå›´: {benign_start} åˆ° {benign_end}")
print(f"  - æ¶æ„å¿«ç…§èŒƒå›´: {malicious_start} åˆ° {malicious_end}")

# ä½¿ç”¨å…¨éƒ¨å¿«ç…§è®­ç»ƒç¼–ç å™¨
print("\n--- ç¼–ç å™¨è®­ç»ƒï¼ˆå…¨éƒ¨æ•°æ®ï¼‰---")
embedder_class = get_embedder_by_name("prographer")
embedder = embedder_class(all_snapshots, sequence_length=SEQUENCE_LENGTH)
embedder.train()  # åœ¨å…¨éƒ¨å¿«ç…§ä¸Šè®­ç»ƒç¼–ç å™¨
all_snapshot_embeddings = embedder.get_snapshot_embeddings()
rsg_embeddings, rsg_vocab = embedder.get_rsg_embeddings()

print("\n--- Encoder process finished ---")
print(f"å·²ç”Ÿæˆå¿«ç…§åµŒå…¥åºåˆ—ï¼Œå½¢çŠ¶ä¸º: {all_snapshot_embeddings.shape}")
print(f"å·²ç”ŸæˆRSGåµŒå…¥çŸ©é˜µï¼Œå½¢çŠ¶ä¸º: {rsg_embeddings.shape}")
print(f"RSGè¯æ±‡è¡¨å¤§å°: {len(rsg_vocab)}")

# ======================== é˜¶æ®µ2ï¼šå¼‚å¸¸æ£€æµ‹å™¨è®­ç»ƒï¼ˆåªç”¨è‰¯æ€§æ•°æ®ï¼‰========================
print("\n" + "="*60)
print("é˜¶æ®µ2ï¼šå¼‚å¸¸æ£€æµ‹å™¨è®­ç»ƒï¼ˆåªç”¨è‰¯æ€§æ•°æ®ï¼‰")
print("="*60)

# æå–è‰¯æ€§å¿«ç…§çš„åµŒå…¥ç”¨äºå¼‚å¸¸æ£€æµ‹å™¨è®­ç»ƒ
if encoder_handler.benign_idx_start != -1:
    benign_embeddings = all_snapshot_embeddings[encoder_handler.benign_idx_start:encoder_handler.benign_idx_end+1]
    
    print(f"å¼‚å¸¸æ£€æµ‹å™¨è®­ç»ƒæ•°æ®ç»Ÿè®¡:")
    print(f"ç”¨äºå¼‚å¸¸æ£€æµ‹å™¨è®­ç»ƒçš„è‰¯æ€§åµŒå…¥å½¢çŠ¶: {benign_embeddings.shape}")
    print(f"è‰¯æ€§å¿«ç…§ç´¢å¼•èŒƒå›´: {encoder_handler.benign_idx_start} åˆ° {encoder_handler.benign_idx_end}")
    
    # è®­ç»ƒå¼‚å¸¸æ£€æµ‹å™¨ï¼ˆåªç”¨è‰¯æ€§åµŒå…¥ï¼‰
    train_model(benign_embeddings, sequence_length_L=SEQUENCE_LENGTH)
    
    print(f"\nâœ… è®­ç»ƒå®Œæˆï¼")
    print(f"  - ç¼–ç å™¨ä½¿ç”¨äº† {len(all_snapshots)} ä¸ªå¿«ç…§ï¼ˆè‰¯æ€§+æ¶æ„ï¼‰")
    print(f"  - å¼‚å¸¸æ£€æµ‹å™¨ä½¿ç”¨äº† {len(benign_embeddings)} ä¸ªè‰¯æ€§å¿«ç…§")
else:
    print("âŒ é”™è¯¯ï¼šæ²¡æœ‰è‰¯æ€§å¿«ç…§å¯ç”¨äºè®­ç»ƒ")